{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importschedule\n",
    "import pandas as pd\n",
    "from account import baseurl,name,password\n",
    "import pickle\n",
    "from doccano_api_client import DoccanoClient\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 1, 'username': 'Punyajoy', 'first_name': 'Punyajoy', 'last_name': 'Saha', 'email': 'punyajoysaha1998@gmail.com', 'is_superuser': True}\n"
     ]
    }
   ],
   "source": [
    "doccano_client = DoccanoClient(\n",
    "    baseurl,name,password\n",
    ")\n",
    "\n",
    "r_me = doccano_client.get_me()\n",
    "\n",
    "# print the details from the above query\n",
    "print(r_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "projects=doccano_client.get_project_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 101,\n",
       "  'name': 'Hatespeech_annotation_Kanishk',\n",
       "  'description': 'Annotation hate speech',\n",
       "  'guideline': 'Please write annotation guideline.',\n",
       "  'users': [56, 2, 1],\n",
       "  'project_type': 'SequenceLabeling',\n",
       "  'image': '/static/assets/images/cats/sequence_labeling.jpg',\n",
       "  'updated_at': '2021-02-10T15:27:14.704373Z',\n",
       "  'randomize_document_order': False,\n",
       "  'resourcetype': 'SequenceLabelingProject'},\n",
       " {'id': 107,\n",
       "  'name': 'Hatexplain_annotation_Punyajoy',\n",
       "  'description': 'rationale_annotation',\n",
       "  'guideline': 'Please write annotation guideline.',\n",
       "  'users': [1],\n",
       "  'project_type': 'SequenceLabeling',\n",
       "  'image': '/static/assets/images/cats/sequence_labeling.jpg',\n",
       "  'updated_at': '2021-05-09T03:26:38.585303Z',\n",
       "  'randomize_document_order': False,\n",
       "  'resourcetype': 'SequenceLabelingProject'},\n",
       " {'id': 120,\n",
       "  'name': 'Fear_hate_project_Aayush',\n",
       "  'description': 'Annotate fear and hate in the given posts',\n",
       "  'guideline': '## Annotation guidelines\\nThere are different forms of toxic speech in the current social media platform. In this task, we plan to annotate speech belonging to the fear and hate category.\\n## Task\\nBased on the message, you have to decide if the text is hate speech, fear speech or normal. A post can be both hate speech and fear speech. \\n\\nIf you are confused about some post, mark the confused as well as the closest label/s that you feel\\n\\nMore details visit [this link](https://drive.google.com/file/d/1AbCXUkFPkZjfOJNTPRPoAYzvz8Ppgtjw/view?usp=sharing)',\n",
       "  'users': [63, 1],\n",
       "  'project_type': 'DocumentClassification',\n",
       "  'image': '/static/assets/images/cats/text_classification.jpg',\n",
       "  'updated_at': '2021-06-19T15:10:05.492550Z',\n",
       "  'randomize_document_order': False,\n",
       "  'resourcetype': 'TextClassificationProject'},\n",
       " {'id': 128,\n",
       "  'name': 'Fear_hate_project_Saurabh',\n",
       "  'description': 'Annotate fear and hate project',\n",
       "  'guideline': '## Annotation guidelines\\nThere are different forms of toxic speech in the current social media platform. In this task, we plan to annotate speech belonging to the fear and hate category.\\n## Task\\nBased on the message, you have to decide if the text is hate speech, fear speech or normal. A post can be both hate speech and fear speech. \\n\\nIf you are confused about some post, mark the confused as well as the closest label/s that you feel\\n\\nMore details visit [this link](https://drive.google.com/file/d/1AbCXUkFPkZjfOJNTPRPoAYzvz8Ppgtjw/view?usp=sharing)',\n",
       "  'users': [61, 1],\n",
       "  'project_type': 'DocumentClassification',\n",
       "  'image': '/static/assets/images/cats/text_classification.jpg',\n",
       "  'updated_at': '2021-06-19T15:10:34.296605Z',\n",
       "  'randomize_document_order': False,\n",
       "  'resourcetype': 'TextClassificationProject'},\n",
       " {'id': 130,\n",
       "  'name': 'Fear_hate_project_Pauras',\n",
       "  'description': 'Annotate fear and hate',\n",
       "  'guideline': '## Annotation guidelines\\nThere are different forms of toxic speech in the current social media platform. In this task, we plan to annotate speech belonging to the fear and hate category.\\n## Task\\nBased on the message, you have to decide if the text is hate speech, fear speech or normal. A post can be both hate speech and fear speech. \\n\\nIf you are confused about some post, mark the confused as well as the closest label/s that you feel\\n\\nMore details visit [this link](https://drive.google.com/file/d/1AbCXUkFPkZjfOJNTPRPoAYzvz8Ppgtjw/view?usp=sharing)',\n",
       "  'users': [1, 62],\n",
       "  'project_type': 'DocumentClassification',\n",
       "  'image': '/static/assets/images/cats/text_classification.jpg',\n",
       "  'updated_at': '2021-06-19T15:11:35.883234Z',\n",
       "  'randomize_document_order': False,\n",
       "  'resourcetype': 'TextClassificationProject'},\n",
       " {'id': 103,\n",
       "  'name': 'Fear and hate project',\n",
       "  'description': 'fear speech and hate speech detection',\n",
       "  'guideline': '## Annotation guidelines\\r\\n\\r\\nThere are different forms of toxic speech in the current social media platform. In this task, we plan to annotate speech belonging to the fear and hate/offensive category.\\r\\n\\r\\n## Task\\r\\n\\r\\nBased on the message, you have to decide if the text is hate speech, offensive speech, fear speech or normal.\\r\\n\\r\\n\\r\\n## Definitions\\r\\n\\r\\n#### Hate speech: \\r\\nThis type of speech express hatred towards a targeted individual or group or is intended to be derogatory, to humiliate, or to insult the members of the group, on the basis of attributes such as race, religion, ethnic origin, sexual orientation, disability, or gender.\\r\\n\\r\\n*It is NOT the presence of certain words that makes the text hate speech, rather you should look at the context in which the word is used in the text.*\\r\\n\\r\\n\\r\\nA post is a Hate speech if:\\r\\n* it is targeted against a person or group of persons\\r\\n* it uses derogatory or racial slur words within the tweet\\r\\n* it makes use of disparaging terms with the intent to harm or incite harm\\r\\n* it refers to and supports other hateful facts, hates tweets and organization\\r\\n* it makes use of idiomatic, metaphorical, collocation or any other indirect means of expressions that are harmful or may incite harm\\r\\n* it expresses violent communications\\r\\n\\r\\n\\r\\n\\r\\n#### Offensive speech: \\r\\n\\r\\nA speech is offensive if it uses profanity, strongly impolite, rude or vulgar language expressed with fighting or hurtful words in order to insult a targeted individual or group.\\r\\n\\r\\nA post is an Offensive speech if:\\r\\n\\r\\n* it is targeted against a person, group of persons or organization\\r\\n* it is not a hate speech\\r\\n* it abuses a target using profane, derogatory or vulgar language\\r\\n\\r\\n\\r\\n#### Fear speech\\r\\n\\r\\nA speech is a fear speech is an expression aimed at instilling (existential) fear in a target group. The fear may be generated in various forms. These forms include but are not limited to:- \\r\\n\\r\\nA post is a Fear speech the post is trying to create fear using:\\r\\n\\r\\n* something is done by the other group in the past (and the possibility of that happening again). \\r\\n* It may be some tradition of the group which is shown to take precedence over in-groups \\r\\n* Speculation showing the target group will take over and dominate in the future over the in group\\r\\n\\r\\n\\r\\n### Remember that a post may be partially fear as well as offensive/hate in nature in different parts of the post',\n",
       "  'users': [57, 2, 1],\n",
       "  'project_type': 'DocumentClassification',\n",
       "  'image': '/static/assets/images/cats/text_classification.jpg',\n",
       "  'updated_at': '2021-03-27T15:26:54.505552Z',\n",
       "  'randomize_document_order': False,\n",
       "  'resourcetype': 'TextClassificationProject'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "list_files_path=sorted(glob.glob('../HULK/Counterspeech/Hate_Non_Hate_05/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_round=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_labels(103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knockknock import slack_sender\n",
    "\n",
    "webhook_url = \"https://hooks.slack.com/services/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\"\n",
    "\n",
    "@slack_sender(webhook_url=webhook_url, channel=\"data_collection_twitter\")\n",
    "def send_status(string1):\n",
    "    return string1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(list_files_path,id_list):\n",
    "    samples_added=0\n",
    "    final_list=[]\n",
    "    for path in list_files_path:\n",
    "        if(samples_added>at_once):\n",
    "            break\n",
    "        with open(path, 'rb') as f:\n",
    "            sentence_list = pickle.load(f)\n",
    "\n",
    "        temp_list=[]\n",
    "        for sentence in sentence_list:\n",
    "            if(sentence['probs'][0]>=0.5 and sentence['probs'][0]<0.8 and sentence['data']['id'] not in id_list):\n",
    "                temp_list.append(sentence)\n",
    "        k= random.randint(0, 10)\n",
    "        k=min(k, len(temp_list))\n",
    "        if(k!=0):\n",
    "            samples_added+=k\n",
    "            sample_list=random.sample(temp_list, k)\n",
    "            final_list+=sample_list\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = re.sub('@\\w+', '@user',text)\n",
    "    new_text = re.sub(u\"(\\u2018|\\u2019|\\u201A|\\u201B|\\u201C|\\u201D|\\u201E)\", \"'\", new_text)\n",
    "    new_text = re.sub(u\"(\\u200d|\\u200c)\", \"\", new_text)\n",
    "    #new_text = new_text.replace(\"\\'\",'\\'')\n",
    "    new_text = new_text.replace(\"\\r\\n\\'\",' ').replace(\"\\n\",' ')\n",
    "    new_text = re.sub(r\"http\\S+\", \"\", new_text)\n",
    "    new_text = new_text.replace('&amp;', '&')\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def project_labels(id1):\n",
    "    label_list=doccano_client.get_label_list(id1)\n",
    "    label_json = {}\n",
    "    for ele in label_list:\n",
    "        label_json[ele['id']]=ele['text']\n",
    "    \n",
    "    return label_json\n",
    "\n",
    "def get_annotated_data(id1):\n",
    "    training_annotated=doccano_client.get_doc_download(id1)\n",
    "    text_data= '[' + re.sub(r'\\}\\n\\{', '},{', training_annotated.text) + ']'\n",
    "    text_data=json.loads(text_data,encoding='utf-8')\n",
    "    return text_data\n",
    "\n",
    "def check_function(labels_dict, dict_project_label):\n",
    "    user_list=[]\n",
    "    for label_rational in labels_dict:\n",
    "        user_list.append(label_rational['user'])\n",
    "    \n",
    "    user_list=set(user_list)\n",
    "    if(len(user_list)==2):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def labels_addition(annotations_dict,dict_project_label):\n",
    "    label_list={}\n",
    "    for label_rational in annotations_dict:\n",
    "        try:\n",
    "            label_list[label_rational['user']].append(dict_project_label[label_rational['label']])\n",
    "        except KeyError:\n",
    "            label_list[label_rational['user']]=[dict_project_label[label_rational['label']]]\n",
    "            \n",
    "    return label_list\n",
    "\n",
    "\n",
    "def count_annotation(id1,check_function):\n",
    "    project_label=project_labels(id1)\n",
    "    text_data=get_annotated_data(id1)\n",
    "    count_complete = 0\n",
    "    count_data = 0\n",
    "    for ele in tqdm.tqdm(text_data):\n",
    "        flag=0\n",
    "        if(check_function(ele['annotations'],project_label)):\n",
    "            count_complete+=1\n",
    "            count_data+=1\n",
    "            flag=1\n",
    "\n",
    "        if(flag==0):\n",
    "            count_data+=1\n",
    "            print(ele)\n",
    "            \n",
    "    dict1={\n",
    "        'complete':count_complete,\n",
    "        'total':count_data   \n",
    "    }\n",
    "    \n",
    "    return dict1\n",
    "                \n",
    "                \n",
    "def read_annotation():\n",
    "    \n",
    "    project_label_dict=project_labels(103)\n",
    "    text_data=get_annotated_data(103)\n",
    "    \n",
    "    json_data={}\n",
    "    for ele in tqdm.tqdm(text_data):\n",
    "        found_id=re.search(r'\\#\\#(.*?)\\#\\#', ele['text']).group(1)\n",
    "        text = re.sub(u\"\\#\\#(.*?)\\#\\#\", \"\", ele['text'])\n",
    "    \n",
    "        temp={}\n",
    "        temp['text']=text\n",
    "        temp['id']=found_id\n",
    "        temp['label']=labels_addition(ele['annotations'],project_label_dict)\n",
    "        json_data[found_id]=temp\n",
    "        \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Project1_stats=count_annotation(103,check_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Project1_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data=read_annotation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "count=0\n",
    "\n",
    "dict_map={'Fear speech':0, 'Hate speech':1 ,'Normal':2, 'offensive':3}\n",
    "\n",
    "annotation_1=np.zeros((189,4))\n",
    "annotation_2=np.zeros((189,4))\n",
    "\n",
    "for dict1 in json_data:\n",
    "    if(len(json_data[dict1]['label'])==2):\n",
    "        for ele in json_data[dict1]['label'][1]:\n",
    "            annotation_1[count][dict_map[ele]]+=1\n",
    "        for ele in json_data[dict1]['label'][57]:\n",
    "            annotation_1[count][dict_map[ele]]+=1\n",
    "        count+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_1=np.zeros((len(json_data)+1,4))\n",
    "count=0\n",
    "\n",
    "for dict1 in json_data:\n",
    "    for ele in json_data[dict1]['label'][1]:\n",
    "        annotation_1[count][dict_map[ele]]+=1\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data[dict1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "\n",
    "hate_fear_offensive={}\n",
    "\n",
    "count_hate =0 \n",
    "count_fear =0 \n",
    "count_off =0 \n",
    "count_fear_hate=0\n",
    "count_fear_off=0\n",
    "count_telegram=0\n",
    "\n",
    "for key in json_data.keys():\n",
    "    if(json_data[key]['label'][1]!=['Normal'] and json_data[key]['label'][1]!=[]):\n",
    "        hate_fear_offensive[key]=json_data[key]\n",
    "        if(key.find('post_id')!=-1):\n",
    "            count_telegram+=1\n",
    "    \n",
    "    \n",
    "    flag_off=flag_hate=flag_fear=0 \n",
    "    \n",
    "    for label in json_data[key]['label'][1]:\n",
    "        if(label=='offensive'):\n",
    "            count_off+=1\n",
    "            flag_off=1\n",
    "        if(label=='Hate speech'):\n",
    "            count_hate+=1\n",
    "            flag_hate=1\n",
    "        if(label=='Fear speech'):\n",
    "            count_fear+=1\n",
    "            flag_fear+=1\n",
    "        if(flag_fear and flag_hate):\n",
    "            count_fear_hate+=1\n",
    "        if(flag_fear and flag_hate):\n",
    "            count_fear_off+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_hate, \n",
    "count_fear, \n",
    "count_off,\n",
    "count_fear_hate,\n",
    "count_fear_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hate_fear_offensive)-count_telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n",
    "\n",
    "krippendorff.alpha(reliability_data=annotation_1,level_of_measurement='nominal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path_annotations='../HULK/Counterspeech/Hate_Annotations/'\n",
    "\n",
    "def send_one_round_annotation(id_list,count_round):\n",
    "    if(count_round==0):\n",
    "        print(\"The annotation begins now\")\n",
    "    else:\n",
    "        print(\"Annotation round\",count_round)\n",
    "    \n",
    "    \n",
    "    Project1_stats=count_annotation(100)\n",
    "    Project2_stats=count_annotation(101)\n",
    "    \n",
    "    \n",
    "    flag=0\n",
    "    if(Project1_stats['complete']<Project1_stats['total']):\n",
    "        flag=1\n",
    "        diff_str1 = \"No. of datapoints remaining for Adarsh:\"+ str(Project1_stats['total']-Project1_stats['complete'])\n",
    "        send_status(diff_str1)\n",
    "    \n",
    "    if(Project2_stats['complete']<Project2_stats['total']):\n",
    "        flag=1\n",
    "        diff_str2 = \"No. of datapoints remaining for Kanishk:\"+ str(Project2_stats['total']-Project2_stats['complete'])\n",
    "        send_status(diff_str2)\n",
    "    \n",
    "    if(flag==1):\n",
    "        print(\"Since current annotation not complete ... not giving newer annotations\")\n",
    "        return id_list,flag,[],count_round\n",
    "    else:\n",
    "        json_data=read_annotation(id_list)\n",
    "        with open(path_annotations+str(count_round)+'.json', 'w') as outfile:\n",
    "            json.dump(json_data, outfile, indent=3, ensure_ascii=False)\n",
    "            \n",
    "        for ele in json_data.keys():\n",
    "            id_list.append(int(ele))\n",
    "    \n",
    "    \n",
    "        count_round+=1\n",
    "    \n",
    "    final_list=get_samples(list_files_path,id_list)\n",
    "    text_list=[]\n",
    "    for data in final_list:\n",
    "        text='$$'+data['data']['id']+'$$  '\n",
    "        text+= preprocess(data['data']['text'])\n",
    "        text_list.append({'text':text})\n",
    "\n",
    "    with open('output.json', 'w') as fout:\n",
    "        for item in text_list:\n",
    "            fout.write(json.dumps(item))\n",
    "            fout.write('\\n')\n",
    "\n",
    "\n",
    "    get_id1=doccano_client.post_doc_upload(100,'json','output.json')\n",
    "    get_id2=doccano_client.post_doc_upload(101,'json','output.json')\n",
    "    return id_list,final_list,flag,count_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_once=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Logs/ids_of_annotations.pkl\",\"rb\") as f:\n",
    "    id_list=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list,final_list,flag,count_round=send_one_round_annotation(id_list,count_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Logs/ids_of_annotations.pkl\",\"wb\")\n",
    "pickle.dump(id_list,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "annotation_files=glob.glob(path_annotations+'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement_scores=[]\n",
    "overlap_scores= []\n",
    "count_hatespeech_all=[]\n",
    "count_normal_all=[]\n",
    "count_total =[]\n",
    "\n",
    "for file in annotation_files:\n",
    "    f = open(file,\"r\") \n",
    "    json_data = json.load(f) \n",
    "    annotators_label_1=[]\n",
    "    annotators_label_2=[]\n",
    "    rationales_temp = []\n",
    "    count_hatespeech=0\n",
    "    count_normal=0\n",
    "    for key in json_data:\n",
    "        labels = json_data[key]['label']\n",
    "        if len(labels)==2:\n",
    "            annotators_label_1.append(labels[0])\n",
    "            annotators_label_2.append(labels[1])\n",
    "            if(labels[0]==labels[1]=='hatespeech'):\n",
    "                count_hatespeech +=1\n",
    "                rationales_all_char=[]\n",
    "                for rationale in json_data[key]['rationales']:\n",
    "                    rationale_char = np.zeros(len(json_data[key]['text']))\n",
    "                    for temp in rationale:\n",
    "                        rationale_char[temp[0]:temp[1]+1] = 1\n",
    "                    rationales_all_char.append(list(rationale_char))\n",
    "                jac_score=jaccard_score(rationales_all_char[0], rationales_all_char[1])\n",
    "                if(jac_score<0.5):\n",
    "                    print(json_data[key])\n",
    "                rationales_temp.append(jac_score)\n",
    "            elif(labels[0]==labels[1]=='normal'):\n",
    "                count_normal +=1\n",
    "    agree_score = cohen_kappa_score(annotators_label_1, annotators_label_2)\n",
    "    agreement_scores.append(agree_score)\n",
    "    overlap_scores.append(np.mean(rationales_temp))\n",
    "    count_hatespeech_all.append(count_hatespeech)\n",
    "    count_normal_all.append(count_normal)\n",
    "    count_total.append(len(json_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'agreement_cohen':agreement_scores,'overlap_score':overlap_scores,'hate_speech_count':count_hatespeech_all,'normal_count':count_normal_all,'total':count_total})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slack_cleaner2 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_A=get_annotated_data(100)\n",
    "text_data_K=get_annotated_data(101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_delete={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_label=project_labels(100)\n",
    "for ele in tqdm.tqdm(text_data_A):\n",
    "    for label_rational in ele['annotations']:\n",
    "        found_id=re.search(r'\\$\\$(.*?)\\$\\$', ele['text']).group(1)\n",
    "        \n",
    "        if(project_label[label_rational['label']] in ['hatespeech','normal','not sure']):\n",
    "                try:\n",
    "                    id_to_delete[found_id].append({100:ele['id']})\n",
    "                except KeyError:\n",
    "                    id_to_delete[found_id]=[{100:ele['id']}]\n",
    "\n",
    "project_label=project_labels(101)\n",
    "for ele in tqdm.tqdm(text_data_K):\n",
    "    for label_rational in ele['annotations']:\n",
    "        found_id=re.search(r'\\$\\$(.*?)\\$\\$', ele['text']).group(1)\n",
    "        if(project_label[label_rational['label']] in ['hatespeech','normal','not sure']):\n",
    "                try:\n",
    "                    id_to_delete[found_id].append({101:ele['id']})\n",
    "                except KeyError:\n",
    "                    id_to_delete[found_id]=[{101:ele['id']}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id1 in id_to_delete:\n",
    "    dict_list=id_to_delete[id1]\n",
    "    for ele in dict_list:\n",
    "        for key in ele.keys():\n",
    "            doccano_client.delete_document(project_id = key, document_id = ele[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doccano_client.delete_document(project_id = 100, document_id = 25613)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "def return_dict_label(project_id):\n",
    "    label_list=doccano_client.get_label_list(project_id)\n",
    "    dict_label={}\n",
    "    for label in label_list:\n",
    "        dict_label[label['id']]=label['text']\n",
    "    return dict_label\n",
    "\n",
    "def get_data_from_user(username,projects):\n",
    "#     project_name=''+username\n",
    "    \n",
    "    for ele in projects:\n",
    "        if(username in ele['name']):\n",
    "            id1=ele['id']\n",
    "    \n",
    "    \n",
    "    labels_dict =  return_dict_label(id1)\n",
    "    training_annotated=doccano_client.get_doc_download(id1)\n",
    "    #print(training_annotated.text)\n",
    "    text_data = '[' + re.sub(r'\\}\\n\\{', '},{', training_annotated.text) + ']'\n",
    "    text_data=json.loads(text_data,encoding='utf8')\n",
    "    print_stats={'Not_done':0,'Wrong_annotation':0,'Completed':0,'Not_found':0}\n",
    "    tuple_data=[]\n",
    "    for ele in tqdm_notebook(text_data):\n",
    "        found_id=re.search(r'\\#\\#(.*?)\\#\\#', ele['text']).group(1)\n",
    "        if(len(ele['annotations'])>0):\n",
    "            print_stats['Completed']+=1\n",
    "            tuple_data.append([ele['id'],id1])\n",
    "        elif(len(ele['annotations'])==0):\n",
    "            print_stats['Not_done']+=1\n",
    "    return tuple_data,print_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pauras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-0d121a20fd78>:21: DeprecationWarning: 'encoding' is ignored and deprecated. It will be removed in Python 3.9\n",
      "  text_data=json.loads(text_data,encoding='utf8')\n",
      "<ipython-input-6-0d121a20fd78>:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for ele in tqdm_notebook(text_data):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b35bb83d784b00a5ff58e25ef91161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'Not_done': 0, 'Wrong_annotation': 0, 'Completed': 4, 'Not_found': 0}\n",
      "Saurabh\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd5fca84ff64c148ff1029c94153b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=202.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'Not_done': 0, 'Wrong_annotation': 0, 'Completed': 202, 'Not_found': 0}\n",
      "Aayush\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee81ead496f34af7bb4f089fc2963342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=202.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'Not_done': 0, 'Wrong_annotation': 0, 'Completed': 202, 'Not_found': 0}\n"
     ]
    }
   ],
   "source": [
    "# users = ['Punyajoy']\n",
    "\n",
    "users=['Pauras','Saurabh','Aayush']\n",
    "\n",
    "\n",
    "for user in users:\n",
    "    print(user)\n",
    "    tuple_data,print_stats=get_data_from_user(user,projects)\n",
    "    print(print_stats)\n",
    "    for element in tuple_data:\n",
    "        doccano_client.delete_document(project_id = element[1], document_id = element[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:twitter_crawler]",
   "language": "python",
   "name": "conda-env-twitter_crawler-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
