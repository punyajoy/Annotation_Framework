{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation data \n",
    "> selecting data for annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from whatsapp_analytics import translation\n",
    "from utils import preprocess\n",
    "import pickle\n",
    "from os import path\n",
    "import parmap\n",
    "import numpy as np\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0\n",
    "from langdetect import detect\n",
    "import re\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path='../Data/New_Data_15-06-2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_translation(df):\n",
    "    translated_text_list=[]\n",
    "    num_keywords =[] \n",
    "    language = []\n",
    "    for index,row in tqdm_notebook(df.iterrows(),total=len(df)):\n",
    "        temp = re.sub(r\"http\\S+\", \"\", row[\"message_text\"])\n",
    "        lang=row['language']\n",
    "        if(lang in ['en','unk']):\n",
    "            translated_text_list.append(temp)\n",
    "        else:\n",
    "            translated_text=translation.translate(row[\"message_text\"],lang,to_preprocess=False)\n",
    "            translated_text_list.append(translated_text)    \n",
    "    df[\"translated\"]=translated_text_list\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def add_keywords(df,type1='hindu'):\n",
    "    filename='../Data/Important_lexicon/'+type1+'_keywords_complete.txt'\n",
    "    keyword_text = open(filename, 'r')\n",
    "    keywords = [line.strip('\\n').lower() for line in keyword_text.readlines()]\n",
    "    \n",
    "    num_keywords =[] \n",
    "    for index,row in tqdm_notebook(df.iterrows(),total=len(df)):\n",
    "        temp = row['tokenized']\n",
    "        keywords_found=[x for x in temp if x in keywords]\n",
    "        count=len(keywords_found)\n",
    "        num_keywords.append(count)\n",
    "    colname=type1+\"_keyword_count\"\n",
    "    df[colname]=num_keywords\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps taken to further to collect the data \n",
    "1. save ids processed for annotation\n",
    "2. add translate \n",
    "3. add keyword\n",
    "4. Add uuids\n",
    "5. save annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "if path.exists(parent_path+'data_processed_for_annotation.pkl'):\n",
    "    processed_df = pd.read_pickle(parent_path+'data_processed_for_annotation.pkl')\n",
    "else:\n",
    "    processed_df=pd.DataFrame(columns=['message_text','translated','keyword_count','repeated','language','unique_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_df = pd.read_csv(parent_path+'Data_text_spam_removed_v02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = pd.read_csv(parent_path+'group_party_affiliation.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_group_annotation=pd.read_csv('../Data/New_Data_15-06-2020/group_annotation/all_annotation_data_round12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_group_type={}\n",
    "for index,row in group_names.iterrows():\n",
    "    dict_group_type[int(row['group_id'])]=row['party_name']\n",
    "    \n",
    "    \n",
    "dict_group_type_new={}\n",
    "for index,row in total_group_annotation.iterrows():\n",
    "    dict_group_type_new[int(row['grpid'])]=row['annotated_punyajoy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(parent_path+'data_processed_for_annotation.pkl')==False:\n",
    "    group_type = []\n",
    "    for index,row in tqdm_notebook(processed_df.iterrows(),total=len(processed_df)):\n",
    "        try:\n",
    "            group_type.append(dict_group_type[row['group_id_anonymized']])\n",
    "        except KeyError:\n",
    "            try:\n",
    "                group_type.append(dict_group_type_new[row['group_id_anonymized']])\n",
    "            except KeyError:\n",
    "                group_type.append('None')\n",
    "\n",
    "    processed_df['group_type']=group_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_df[processed_df['group_type']=='None']['group_id_anonymized'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_df=processed_df.loc[:, ~processed_df.columns.str.match('Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(parent_path+'data_processed_for_annotation.pkl')==False:\n",
    "    processed_df=preprocess(processed_df)\n",
    "    processed_df=add_keywords(processed_df,type1='hindu')\n",
    "    processed_df=add_keywords(processed_df,type1='muslim')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_df=add_keywords(processed_df,type1='muslim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(parent_path+'data_id_to_uuid.pkl'):\n",
    "    with open(parent_path+'data_id_to_uuid.pkl', 'rb') as f:\n",
    "        mapping = pickle.load(f)\n",
    "else:\n",
    "    mapping = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(parent_path+'data_processed_for_annotation.pkl')==False:\n",
    "    num_annotators_per_text=3\n",
    "    list_of_unique_ids=[]\n",
    "    for index,row in tqdm_notebook(processed_df.iterrows(),total=len(processed_df)):\n",
    "        list_of_mapping=[]\n",
    "        for i in range(num_annotators_per_text):\n",
    "            id1=str(uuid.uuid4())\n",
    "            list_of_mapping.append(id1)\n",
    "            mapping[id1]=index+previous_len\n",
    "        list_of_unique_ids.append(list_of_mapping)\n",
    "    processed_df['unique_ids']=list_of_unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'previous_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-eb2e01e4689b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprevious_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'previous_len' is not defined"
     ]
    }
   ],
   "source": [
    "previous_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide \n",
    "## saving the whole results to be used later\n",
    "if path.exists(parent_path+'data_processed_for_annotation.pkl')==False:\n",
    "    with open(parent_path+'data_id_to_uuid.pkl', 'wb') as f:\n",
    "        pickle.dump(mapping,f)\n",
    "    processed_df.to_pickle(parent_path+'data_processed_for_annotation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_df.to_pickle(parent_path+'data_processed_for_annotation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id_anonymized</th>\n",
       "      <th>phone_num_anonymized</th>\n",
       "      <th>message_text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>media_type</th>\n",
       "      <th>media_url</th>\n",
       "      <th>forwarded</th>\n",
       "      <th>orig_index</th>\n",
       "      <th>language</th>\n",
       "      <th>only_urls</th>\n",
       "      <th>is_spam</th>\n",
       "      <th>group_type</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>hindu_keyword_count</th>\n",
       "      <th>muslim_keyword_count</th>\n",
       "      <th>unique_ids</th>\n",
       "      <th>preds</th>\n",
       "      <th>pred_probab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>కోడెల కుల ప్రసంగం :-   వేల కోట్లు ఖర్చు పెట్టి...</td>\n",
       "      <td>1549564818000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>te</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YSRCP</td>\n",
       "      <td>[కోడెల, కుల, ప్రసంగం, వేల, కోట్లు, ఖర్చు, పెట్...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[d5c46b9b-529f-41d5-b13f-3ce7d87167af, 34ec1f7...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Chirala mla paristiti enti frnds cheppandi</td>\n",
       "      <td>1549559412000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YSRCP</td>\n",
       "      <td>[chirala, mla, paristiti, enti, frnds, cheppandi]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[fae5c0c6-4803-4d4f-b18a-e5f18f16d66f, de1cdad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.053958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Dilli me aaj ole</td>\n",
       "      <td>1549559506000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>et</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BJP</td>\n",
       "      <td>[dilli, me, aaj, ole]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[b1cbc961-5c4d-450a-91d5-71a66d43494f, 2c7f282...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Me gajendra dilli</td>\n",
       "      <td>1549559512000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>sq</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BJP</td>\n",
       "      <td>[me, gajendra, dilli]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[6de62602-6f1b-4f60-8d5c-238837f50657, 9adceea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.657664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>*लघु सिंचाई*  निःशुल्क बोरिंग योजना हेतु 55 कर...</td>\n",
       "      <td>1549559608000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>hi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "      <td>[लघु, सिंचाई, निःशुल्क, बोरिंग, योजना, हेतु, क...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[f265737e-0dd2-4cd8-9f31-5220a94c8dba, c7d9c2a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id_anonymized  phone_num_anonymized  \\\n",
       "0                    4                     4   \n",
       "1                    5                     5   \n",
       "2                    9                     9   \n",
       "3                    9                     9   \n",
       "4                   13                    12   \n",
       "\n",
       "                                        message_text      timestamp  \\\n",
       "0  కోడెల కుల ప్రసంగం :-   వేల కోట్లు ఖర్చు పెట్టి...  1549564818000   \n",
       "1         Chirala mla paristiti enti frnds cheppandi  1549559412000   \n",
       "2                                   Dilli me aaj ole  1549559506000   \n",
       "3                                  Me gajendra dilli  1549559512000   \n",
       "4  *लघु सिंचाई*  निःशुल्क बोरिंग योजना हेतु 55 कर...  1549559608000   \n",
       "\n",
       "  media_type media_url  forwarded  orig_index language  only_urls  is_spam  \\\n",
       "0       None      None          1           3       te          0        0   \n",
       "1       None      None          0           4       it          0        0   \n",
       "2       None      None          0          10       et          0        0   \n",
       "3       None      None          0          11       sq          0        0   \n",
       "4       None      None          1          16       hi          0        0   \n",
       "\n",
       "  group_type                                          tokenized  \\\n",
       "0      YSRCP  [కోడెల, కుల, ప్రసంగం, వేల, కోట్లు, ఖర్చు, పెట్...   \n",
       "1      YSRCP  [chirala, mla, paristiti, enti, frnds, cheppandi]   \n",
       "2        BJP                              [dilli, me, aaj, ole]   \n",
       "3        BJP                              [me, gajendra, dilli]   \n",
       "4         SP  [लघु, सिंचाई, निःशुल्क, बोरिंग, योजना, हेतु, क...   \n",
       "\n",
       "   hindu_keyword_count  muslim_keyword_count  \\\n",
       "0                    0                     0   \n",
       "1                    0                     0   \n",
       "2                    0                     0   \n",
       "3                    0                     0   \n",
       "4                    0                     0   \n",
       "\n",
       "                                          unique_ids  preds  pred_probab  \n",
       "0  [d5c46b9b-529f-41d5-b13f-3ce7d87167af, 34ec1f7...      0     0.008496  \n",
       "1  [fae5c0c6-4803-4d4f-b18a-e5f18f16d66f, de1cdad...      0     0.053958  \n",
       "2  [b1cbc961-5c4d-450a-91d5-71a66d43494f, 2c7f282...      0     0.126118  \n",
       "3  [6de62602-6f1b-4f60-8d5c-238837f50657, 9adceea...      1     0.657664  \n",
       "4  [f265737e-0dd2-4cd8-9f31-5220a94c8dba, c7d9c2a...      0     0.005101  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection function for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "def model_based_selection(annotated_data,unlabeled_data,model='lr'):\n",
    "    ## curently implements random\n",
    "    sample_df=unlabeled_data.sample(num_data_points)\n",
    "    return sample_df\n",
    "\n",
    "def select_data(unlabeled_data,ids_done,num_data_points=200,way_of_selection='random', num_keywords_hindu=0,num_keywords_muslim=3,parties_to_consider=['BJP','HINDU'],thresh=0.7):\n",
    "    temp=unlabeled_data.drop(list(ids_done))\n",
    "    if(parties_to_consider ==['all']):\n",
    "        temp=temp[temp['pred_probab'] >= thresh]\n",
    "    else:\n",
    "        temp=temp[(temp['group_type'].isin(parties_to_consider)) & (temp['pred_probab'] >= thresh)]\n",
    "    if(way_of_selection=='random'):\n",
    "        sample_df=temp.sample(num_data_points)\n",
    "    elif(way_of_selection=='keyword_based'):\n",
    "        filtered_data=temp[(temp['hindu_keyword_count']>=num_keywords_hindu) & (temp['muslim_keyword_count']>=num_keywords_muslim)]\n",
    "        print(len(filtered_data))\n",
    "        sample_df=filtered_data.sample(num_data_points)\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(parent_path+'annotated_ids.pkl'):\n",
    "    with open(parent_path+'annotated_ids.pkl', 'rb') as f:\n",
    "        ids_done = pickle.load(f)\n",
    "else:\n",
    "    ids_done = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['YSRCP', 'DOUBT', 'JANASENA', 'HINDU', 'OTHERS', 'SP', 'CASTE',\n",
       "       'BJP', 'MUSLIM', 'AAP', 'TMC', 'RJD', 'CONGRESS', 'AIMIM', 'BSP',\n",
       "       'O', 'NCP', 'Anti-BJP', 'NEWS', 'HATE', 'TRS', 'AntiBJP',\n",
       "       'Abhinav Rajasthan Party', 'SFI', 'Jansatta Dal', 'AntiCONGRESS',\n",
       "       'TDP', 'RLP', 'Hate'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_group_annotation['annotated_punyajoy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_df=select_data(processed_df,ids_done,num_data_points=2000,way_of_selection='keyword_based',num_keywords_hindu=0,num_keywords_muslim=2,parties_to_consider=['BJP','HINDU','DOUBT','OTHER','HATE','Hate','CONGRESS','AntiBJP','AntiCONGRESS'], thresh=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6503\n"
     ]
    }
   ],
   "source": [
    "sample_df=select_data(processed_df,ids_done,num_data_points=4000,way_of_selection='keyword_based',num_keywords_hindu=0,num_keywords_muslim=2,parties_to_consider=['BJP','HINDU','OTHER','HATE','Hate','DOUBT'], thresh=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whatsapp_analytics.marking_similars import *\n",
    "thresh_to_consider = 0.7\n",
    "\n",
    "def remove_duplicates_within(sample_df):\n",
    "    sample_df=add_signatures(sample_df,numHashes)\n",
    "    id_done=0\n",
    "    duplicate={}\n",
    "    for index,row in tqdm_notebook(sample_df.iterrows(),total=len(sample_df)):\n",
    "        id_done+=1\n",
    "        try:\n",
    "            temp_dupl=duplicate[index]\n",
    "            continue\n",
    "        except KeyError:\n",
    "            temp=sample_df[id_done:]\n",
    "            for index1,row1 in temp.iterrows():\n",
    "                try:\n",
    "                    temp_dupl=duplicate[index]\n",
    "                    continue\n",
    "                except KeyError:\n",
    "                    signature1=row['signatures']\n",
    "                    signature2=row1['signatures']\n",
    "                    count=0\n",
    "                    for k in range(0, numHashes):\n",
    "                        count = count + (signature1[k] == signature2[k])\n",
    "                    # add to tuple similar if greater than thresh    \n",
    "                    if((count/numHashes)>thresh_to_consider):\n",
    "                        duplicate[index1]=1\n",
    "    \n",
    "    sample_df=sample_df.drop(list(duplicate.keys()))\n",
    "    return sample_df\n",
    "\n",
    "\n",
    "def remove_duplicates_ext(sample_df,total_annotation):\n",
    "    df_total=pd.concat([sample_df,total_annotation])\n",
    "    df_total=add_signatures(df_total,numHashes)\n",
    "    sample_df=df_total[0:len(sample_df)]\n",
    "    total_annotation=df_total[len(sample_df):]\n",
    "    duplicate={}\n",
    "    for index,row in tqdm_notebook(sample_df.iterrows(),total=len(sample_df)):\n",
    "        for index1,row1 in total_annotation.iterrows():\n",
    "            signature1=row['signatures']\n",
    "            signature2=row1['signatures']\n",
    "            count=0\n",
    "            for k in range(0, numHashes):\n",
    "                count = count + (signature1[k] == signature2[k])\n",
    "            # add to tuple similar if greater than thresh    \n",
    "            if((count/numHashes)>thresh_to_consider):\n",
    "                duplicate[index]=1\n",
    "    sample_df=sample_df.drop(list(duplicate.keys()))\n",
    "    return sample_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "annotation_data='../Data/Annotations_to_send/*'\n",
    "filenames=glob(annotation_data)\n",
    "\n",
    "list_df=[]\n",
    "for file in filenames:\n",
    "    if(file[-3:]=='pkl'):\n",
    "        df=pd.read_pickle(file)\n",
    "    if(file[-3:]=='csv'):\n",
    "        df=pd.read_csv(file)\n",
    "    list_df.append(df)\n",
    "\n",
    "    \n",
    "df_total=pd.concat(list_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:08<00:00, 496.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1710566\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebd6f74672f4470a129118942b9fab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  0%|          | 30/7331 [00:00<00:25, 288.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7331/7331 [00:15<00:00, 460.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3328616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b21c7c08d63482991a4089a4cc85b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1603), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df_red=remove_duplicates_within(sample_df)\n",
    "sample_df_final=remove_duplicates_ext(sample_df_red,df_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_final=sample_df_final[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40b58f33de645fea504f87c38c3a699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_process = 10\n",
    "size=100\n",
    "list_df=[]\n",
    "for i in tqdm_notebook(range(0,len(sample_df_final),size)):\n",
    "    df_split = np.array_split(sample_df_final[i:i+size], n_process)\n",
    "    df_list = parmap.map(add_translation, df_split,pm_processes=n_process)    \n",
    "    new_df_processed = pd.concat(df_list,ignore_index=True)\n",
    "    list_df.append(new_df_processed)\n",
    "\n",
    "sample_df_final= pd.concat(list_df,ignore_index=True)\n",
    "    \n",
    "\n",
    "#sample_df_final=add_translation(sample_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_to_check=sample_df_final[['message_text','translated','group_type','orig_index','muslim_keyword_count','hindu_keyword_count']][20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_text</th>\n",
       "      <th>translated</th>\n",
       "      <th>group_type</th>\n",
       "      <th>orig_index</th>\n",
       "      <th>muslim_keyword_count</th>\n",
       "      <th>hindu_keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>मै हूँ ऐसा हिंदू..||  जो मुल्लो की बहन चोदने म...</td>\n",
       "      <td>I am such a Hindu .. || The one who is Mulloy'...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>3806603.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>#कोंग्रेस और उसके सहयोगी दल #पाकिस्तान_परस्त क...</td>\n",
       "      <td>Why are #Congress and its allies #Pakistan_Par...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>3879566.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>*🚩🌞धर्म संस्थापनार्थाय🌞🚩*  *⛳🇮🇳 सनातन धर्म की ...</td>\n",
       "      <td>* 🚩 🌞   Religion for the 🚩  🌞 🇮 🇳   ⛳   Establ...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2448924.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BEFORE YOU SURRENDER YOUR GUNS TO THE POLICE O...</td>\n",
       "      <td>BEFORE YOU SURRENDER YOUR GUNS TO THE POLICE O...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>4718214.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>कश्मीर का इस्लामीकरण: हिन्दुओं को सीख  डॉ विवे...</td>\n",
       "      <td>Islamization of Kashmir: Learning to Hindus Dr...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>5144608.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>*😡😡😡 ये है ईसाई मिशनरियों का धर्मान्तरण का और ...</td>\n",
       "      <td>* 😡 😡  😡   है This is the conversion of Christ...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>5345582.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>सम्राट अशोक का अहिंसक बौद्ध बनना हिन्दुत्व की ...</td>\n",
       "      <td>Emperor Ashoka's becoming a non-violent Buddhi...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>2953482.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>हमारे गौरवशाली इतिहास का एक प्रेरणादायक पृष्ठ ...</td>\n",
       "      <td>An inspirational page of our glorious history,...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>5223531.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>पत्नी बार बार मां पर इल्जाम लगाए जा रही थी.......</td>\n",
       "      <td>The wife was repeatedly blaming the mother …… ...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>4795592.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ख़ौफ़ज़दा महबूबा : जो बोया था वो काटने का समय ...</td>\n",
       "      <td>Khoufzada Mehbooba: Do not commit the crime of...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>1537216.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>So now #China will taste how it’s about suppor...</td>\n",
       "      <td>So now #China will taste how it’s about suppor...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>6082611.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>दुनिया का मात्र एक ऐसा धर्म जिसका नाम इस्लाम ह...</td>\n",
       "      <td>The only religion in the world whose name is I...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>1548668.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>सहारनपुर में एक सिपाही ने न्यूज़ ग्रुप में डाली...</td>\n",
       "      <td>A soldier in Saharanpur posted a poisonous pos...</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>1745899.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>संस्कृत , संस्कृति और #इन्डोनेशिया ___________...</td>\n",
       "      <td>Sanskrit, culture and #Indonesia _____________...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>2612018.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NOTA दबाने से पहले अपने बच्चों का भी सोच लेना,...</td>\n",
       "      <td>Before suppressing NOTA, also think of your ch...</td>\n",
       "      <td>HINDU</td>\n",
       "      <td>5749856.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>आज ईद है और योगी जी का जन्मदिन भी कहीं योगी जी...</td>\n",
       "      <td>Today is Eid and Yogi ji's birthday is also Yo...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>4275424.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>कमलनाथ की हिंदुओ को खत्म करने वाली बात को मज़ाक...</td>\n",
       "      <td>What was the master plan of Congressmen to dis...</td>\n",
       "      <td>HINDU</td>\n",
       "      <td>5389333.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Amitbhai For whom Hindu has to be united We ha...</td>\n",
       "      <td>Amitbhai For whom Hindu has to be united We ha...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>431080.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>*प्रशासक समिति*✊🚩   💪💪💪🚩 *बाबा बन्दा_बैरागी_जी...</td>\n",
       "      <td>* Administrator ✊ 🚩  💪 💪 🚩   💪    Committee * ...</td>\n",
       "      <td>HINDU</td>\n",
       "      <td>5387605.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>हिन्दू महिला को इस्लाम कुबूल करवाते बंगलादेशी ...</td>\n",
       "      <td>Bangladeshi peacekeepers who convert Hindu wom...</td>\n",
       "      <td>BJP</td>\n",
       "      <td>2959467.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         message_text  \\\n",
       "20  मै हूँ ऐसा हिंदू..||  जो मुल्लो की बहन चोदने म...   \n",
       "21  #कोंग्रेस और उसके सहयोगी दल #पाकिस्तान_परस्त क...   \n",
       "22  *🚩🌞धर्म संस्थापनार्थाय🌞🚩*  *⛳🇮🇳 सनातन धर्म की ...   \n",
       "23  BEFORE YOU SURRENDER YOUR GUNS TO THE POLICE O...   \n",
       "24  कश्मीर का इस्लामीकरण: हिन्दुओं को सीख  डॉ विवे...   \n",
       "25  *😡😡😡 ये है ईसाई मिशनरियों का धर्मान्तरण का और ...   \n",
       "26  सम्राट अशोक का अहिंसक बौद्ध बनना हिन्दुत्व की ...   \n",
       "27  हमारे गौरवशाली इतिहास का एक प्रेरणादायक पृष्ठ ...   \n",
       "28  पत्नी बार बार मां पर इल्जाम लगाए जा रही थी.......   \n",
       "29  ख़ौफ़ज़दा महबूबा : जो बोया था वो काटने का समय ...   \n",
       "30  So now #China will taste how it’s about suppor...   \n",
       "31  दुनिया का मात्र एक ऐसा धर्म जिसका नाम इस्लाम ह...   \n",
       "32  सहारनपुर में एक सिपाही ने न्यूज़ ग्रुप में डाली...   \n",
       "33  संस्कृत , संस्कृति और #इन्डोनेशिया ___________...   \n",
       "34  NOTA दबाने से पहले अपने बच्चों का भी सोच लेना,...   \n",
       "35  आज ईद है और योगी जी का जन्मदिन भी कहीं योगी जी...   \n",
       "36  कमलनाथ की हिंदुओ को खत्म करने वाली बात को मज़ाक...   \n",
       "37  Amitbhai For whom Hindu has to be united We ha...   \n",
       "38  *प्रशासक समिति*✊🚩   💪💪💪🚩 *बाबा बन्दा_बैरागी_जी...   \n",
       "39  हिन्दू महिला को इस्लाम कुबूल करवाते बंगलादेशी ...   \n",
       "\n",
       "                                           translated group_type  orig_index  \\\n",
       "20  I am such a Hindu .. || The one who is Mulloy'...      OTHER   3806603.0   \n",
       "21  Why are #Congress and its allies #Pakistan_Par...        BJP   3879566.0   \n",
       "22  * 🚩 🌞   Religion for the 🚩  🌞 🇮 🇳   ⛳   Establ...      OTHER   2448924.0   \n",
       "23  BEFORE YOU SURRENDER YOUR GUNS TO THE POLICE O...      OTHER   4718214.0   \n",
       "24  Islamization of Kashmir: Learning to Hindus Dr...      OTHER   5144608.0   \n",
       "25  * 😡 😡  😡   है This is the conversion of Christ...        BJP   5345582.0   \n",
       "26  Emperor Ashoka's becoming a non-violent Buddhi...        BJP   2953482.0   \n",
       "27  An inspirational page of our glorious history,...        BJP   5223531.0   \n",
       "28  The wife was repeatedly blaming the mother …… ...        BJP   4795592.0   \n",
       "29  Khoufzada Mehbooba: Do not commit the crime of...        BJP   1537216.0   \n",
       "30  So now #China will taste how it’s about suppor...        BJP   6082611.0   \n",
       "31  The only religion in the world whose name is I...        BJP   1548668.0   \n",
       "32  A soldier in Saharanpur posted a poisonous pos...      OTHER   1745899.0   \n",
       "33  Sanskrit, culture and #Indonesia _____________...        BJP   2612018.0   \n",
       "34  Before suppressing NOTA, also think of your ch...      HINDU   5749856.0   \n",
       "35  Today is Eid and Yogi ji's birthday is also Yo...        BJP   4275424.0   \n",
       "36  What was the master plan of Congressmen to dis...      HINDU   5389333.0   \n",
       "37  Amitbhai For whom Hindu has to be united We ha...        BJP    431080.0   \n",
       "38  * Administrator ✊ 🚩  💪 💪 🚩   💪    Committee * ...      HINDU   5387605.0   \n",
       "39  Bangladeshi peacekeepers who convert Hindu wom...        BJP   2959467.0   \n",
       "\n",
       "    muslim_keyword_count  hindu_keyword_count  \n",
       "20                  13.0                  8.0  \n",
       "21                   3.0                  0.0  \n",
       "22                   2.0                  5.0  \n",
       "23                   2.0                  0.0  \n",
       "24                   9.0                 12.0  \n",
       "25                   3.0                  6.0  \n",
       "26                   3.0                  8.0  \n",
       "27                   3.0                  6.0  \n",
       "28                   2.0                  0.0  \n",
       "29                   7.0                  4.0  \n",
       "30                   2.0                  0.0  \n",
       "31                   2.0                  0.0  \n",
       "32                   3.0                  0.0  \n",
       "33                   4.0                  1.0  \n",
       "34                   2.0                  2.0  \n",
       "35                   3.0                  0.0  \n",
       "36                   2.0                 10.0  \n",
       "37                   2.0                  2.0  \n",
       "38                   3.0                  2.0  \n",
       "39                   2.0                  8.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_to_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_to_check['Annotation']=['None']*len(temp_to_check)\n",
    "temp_to_check.to_csv('pilot-checking_fear_speech_round10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only proceed if data is approved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_done += list(sample_df_final.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parent_path+'annotated_ids.pkl', 'wb') as f:\n",
    "        pickle.dump(ids_done,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(parent_path+'round_info.pkl'):\n",
    "    with open(parent_path+'round_info.pkl', 'rb') as f:\n",
    "        round_info = pickle.load(f)\n",
    "else:\n",
    "    round_info = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_final=sample_df_final[['forwarded', 'group_id_anonymized', 'group_type',\n",
    "       'hindu_keyword_count', 'language', 'message_text', 'muslim_keyword_count', 'orig_index', 'phone_num_anonymized', 'timestamp', 'translated', 'unique_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_info+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_data='../Data/Annotations_to_send/'\n",
    "sample_df_final.to_pickle(annotation_data+'annotation_'+str(round_info)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parent_path+'round_info.pkl', 'wb') as f:\n",
    "    pickle.dump(round_info,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "sample_df_final[['message_text']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-.conda-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
