{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from framework\n",
    "> Reading data from the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from whatsapp_analytics import translation\n",
    "import pickle\n",
    "from os import path\n",
    "import parmap\n",
    "import numpy as np\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0\n",
    "from langdetect import detect\n",
    "import re\n",
    "import uuid\n",
    "from account import baseurl,name,password\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "parent_path='../Data/New_Data_15-06-2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: It is not secure to place API token in your source code. You should treat it as a password to your account. It is strongly recommended to use NEPTUNE_API_TOKEN environment variable instead. Remember not to upload source file with API token to any public repository.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Project(Hatespeech-CNERG/Annotation-Database)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "from apiconfig import  project_name,proxies,api_token\n",
    "# The init() function called this way assumes that \n",
    "# NEPTUNE_API_TOKEN environment variable is defined.\n",
    "neptune.init(project_name,api_token=api_token)\n",
    "neptune.set_project(project_name)\n",
    "# log some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune.create_experiment('Fear speech annotation',send_hardware_metrics=False,run_monitoring_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(parent_path+'round_info.pkl'):\n",
    "    with open(parent_path+'round_info.pkl', 'rb') as f:\n",
    "        round_info = pickle.load(f)\n",
    "else:\n",
    "    print(\"no_round_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_info=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doccano_api_client import DoccanoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{'id': 1, 'username': 'Punyajoy', 'first_name': 'Punyajoy', 'last_name': 'Saha', 'email': 'punyajoysaha1998@gmail.com', 'is_superuser': True}\n"
     ]
    }
   ],
   "source": [
    "doccano_client = DoccanoClient(\n",
    "    baseurl,name,password\n",
    ")\n",
    "\n",
    "# get basic information about the authorized user\n",
    "r_me = doccano_client.get_me()\n",
    "\n",
    "# print the details from the above query\n",
    "print(r_me.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "projects=doccano_client.get_project_list().json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user_dict.json') as f:\n",
    "    user_dict_keyname = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Divyanshu': {'id': 41, 'count': 300},\n",
       " 'Debayu': {'id': 44, 'count': 0},\n",
       " 'Danish': {'id': 54, 'count': 0},\n",
       " 'Sharat': {'id': 53, 'count': 300},\n",
       " 'Kukkadapu': {'id': 50, 'count': 301},\n",
       " 'Adarsh': {'id': 52, 'count': 0},\n",
       " 'Yuvraj': {'id': 49, 'count': 300},\n",
       " 'Vineeth': {'id': 51, 'count': 299},\n",
       " 'Samanway': {'id': 45, 'count': 0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dict_keyname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/New_Data_22-05-2020/data_id_to_uuid.pkl', 'rb') as f:\n",
    "        mapping1 = pickle.load(f)\n",
    "with open('../Data/New_Data_15-06-2020/data_id_to_uuid.pkl', 'rb') as f:\n",
    "        mapping2 = pickle.load(f)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_ignore = ['Danish','Samanway']\n",
    "\n",
    "def return_dict_label(project_id):\n",
    "    label_list=doccano_client.get_label_list(project_id).json()\n",
    "    dict_label={}\n",
    "    for label in label_list:\n",
    "        dict_label[label['id']]=label['text']\n",
    "    return dict_label\n",
    "\n",
    "def get_data_from_user(username,projects,mapping):\n",
    "    project_name='Annotation_'+username\n",
    "    user_id=user_dict_keyname[username]['id']\n",
    "    print(username)\n",
    "    for ele in projects:\n",
    "        if(ele['name']==project_name):\n",
    "            id1=ele['id']\n",
    "    labels_dict =  return_dict_label(id1)\n",
    "    training_annotated=doccano_client.get_doc_download(id1)\n",
    "    #print(training_annotated.text)\n",
    "    text_data = '[' + re.sub(r'\\}\\n\\{', '},{', training_annotated.text) + ']'\n",
    "    text_data=json.loads(text_data,encoding='utf8')\n",
    "    print_stats={'Not_done':0,'Wrong_annotation':0,'Completed':0,'Not_found':0}\n",
    "    tuple_data=[]\n",
    "    \n",
    "    for ele in tqdm.tqdm(text_data):\n",
    "        found_id=re.search(r'\\$\\$(.*?)\\$\\$', ele['text']).group(1)\n",
    "        if(len(ele['annotations'])==1):\n",
    "            if(ele['annotations'][0]['user']==user_id):\n",
    "                try:\n",
    "                    tuple_data.append((mapping[found_id],labels_dict[ele['annotations'][0]['label']],username))\n",
    "                    print_stats['Completed']+=1\n",
    "                except KeyError:\n",
    "                    print_stats['Not_found']+=1 \n",
    "            else:\n",
    "                print_stats['Not_done']+=1 \n",
    "        elif(len(ele['annotations'])==0):\n",
    "            print_stats['Not_done']+=1\n",
    "        else:\n",
    "            print(found_id)\n",
    "            print_stats['Wrong_annotation']+=1\n",
    "    print(print_stats)\n",
    "    return tuple_data,print_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divyanshu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3228/3228 [00:00<00:00, 68974.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not_done': 0, 'Wrong_annotation': 0, 'Completed': 2728, 'Not_found': 500}\n",
      "Debayu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2657/2657 [00:00<00:00, 71338.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not_done': 0, 'Wrong_annotation': 0, 'Completed': 2405, 'Not_found': 252}\n",
      "Sharat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2653/2653 [00:00<00:00, 84829.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not_done': 249, 'Wrong_annotation': 0, 'Completed': 1904, 'Not_found': 500}\n",
      "Kukkadapu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3228/3228 [00:00<00:00, 79309.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not_done': 0, 'Wrong_annotation': 0, 'Completed': 2727, 'Not_found': 501}\n",
      "Adarsh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1170/1170 [00:00<00:00, 52616.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not_done': 271, 'Wrong_annotation': 0, 'Completed': 649, 'Not_found': 250}\n",
      "Yuvraj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3229/3229 [00:00<00:00, 86063.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not_done': 210, 'Wrong_annotation': 0, 'Completed': 2527, 'Not_found': 492}\n",
      "Vineeth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2082/2082 [00:00<00:00, 91782.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Not_done': 0, 'Wrong_annotation': 0, 'Completed': 1581, 'Not_found': 501}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dict_ids_annotation={}\n",
    "dict_user_annotation={}\n",
    "\n",
    "dict_stats={}\n",
    "for user in user_dict_keyname.keys():\n",
    "    if(user not in users_to_ignore):\n",
    "        tuple_data,print_stats=get_data_from_user(user,projects,mapping2)\n",
    "        for data in tuple_data:\n",
    "            try:\n",
    "                dict_ids_annotation[data[0]].append(data[1])\n",
    "                dict_user_annotation[data[0]].append(data[2])\n",
    "            except:\n",
    "                dict_ids_annotation[data[0]]=[data[1]]\n",
    "                dict_user_annotation[data[0]]=[data[2]]\n",
    "        dict_stats[user]=print_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Divyanshu</th>\n",
       "      <th>Debayu</th>\n",
       "      <th>Sharat</th>\n",
       "      <th>Kukkadapu</th>\n",
       "      <th>Adarsh</th>\n",
       "      <th>Yuvraj</th>\n",
       "      <th>Vineeth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not_done</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wrong_annotation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Completed</th>\n",
       "      <td>2728</td>\n",
       "      <td>2405</td>\n",
       "      <td>1904</td>\n",
       "      <td>2727</td>\n",
       "      <td>649</td>\n",
       "      <td>2527</td>\n",
       "      <td>1581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not_found</th>\n",
       "      <td>500</td>\n",
       "      <td>252</td>\n",
       "      <td>500</td>\n",
       "      <td>501</td>\n",
       "      <td>250</td>\n",
       "      <td>492</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Divyanshu  Debayu  Sharat  Kukkadapu  Adarsh  Yuvraj  \\\n",
       "Not_done                  0       0     249          0     271     210   \n",
       "Wrong_annotation          0       0       0          0       0       0   \n",
       "Completed              2728    2405    1904       2727     649    2527   \n",
       "Not_found               500     252     500        501     250     492   \n",
       "\n",
       "                  Vineeth  \n",
       "Not_done                0  \n",
       "Wrong_annotation        0  \n",
       "Completed            1581  \n",
       "Not_found             501  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_stats=pd.DataFrame(dict_stats)\n",
    "temp_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df=pd.read_pickle(parent_path+'data_processed_for_annotation.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueIndexes(l):\n",
    "    seen = set()\n",
    "    res = []\n",
    "    for i, n in enumerate(l):\n",
    "        if n not in seen:\n",
    "            res.append(i)\n",
    "            seen.add(n)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def return_fleiss_kappa(df):\n",
    "    dict_map={'Fear speech':1,'Normal':0,'Not_Sure':0}\n",
    "    listM=[]\n",
    "    df=df[~((df['Annotation1']=='No_Annotation') | (df['Annotation2']=='No_Annotation') | ( df['Annotation3']=='No_Annotation'))]\n",
    "    \n",
    "    for index,row in df.iterrows():\n",
    "        annotation_list=[0,0]\n",
    "        annotation_list[dict_map[row['Annotation1']]]+=1\n",
    "        annotation_list[dict_map[row['Annotation2']]]+=1\n",
    "        annotation_list[dict_map[row['Annotation3']]]+=1\n",
    "        listM.append(annotation_list)\n",
    "    temp=fleiss_kappa(listM)\n",
    "    if(math.isnan(temp)):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return temp\n",
    "\n",
    "    \n",
    "def return_class_count(df):\n",
    "    dict_map={'Fear speech':1,'Normal':0}\n",
    "    fear_count=0\n",
    "    normal_count=0\n",
    "    for index,row in df.iterrows():\n",
    "        annotation_list=[0,0]\n",
    "        try:\n",
    "            annotation_list[dict_map[row['Annotation1']]]+=1\n",
    "            annotation_list[dict_map[row['Annotation2']]]+=1\n",
    "            annotation_list[dict_map[row['Annotation3']]]+=1\n",
    "        except:\n",
    "            annotation_list[0]=3\n",
    "            print(index)\n",
    "        if(annotation_list[1]>=annotation_list[0]):\n",
    "            fear_count+=1\n",
    "        else:\n",
    "            normal_count+=1\n",
    "        \n",
    "        #listM.append(annotation_list)\n",
    "    return fear_count,normal_count\n",
    "    \n",
    "    \n",
    "def return_cohen_kappa_onevs_all(df,username):\n",
    "    pair_tuples=[]\n",
    "    for index,row in df.iterrows():\n",
    "        pair_tuples.append((row['Annotation1'],row['User1'],row['Annotation2'],row['User2']))\n",
    "        pair_tuples.append((row['Annotation1'],row['User1'],row['Annotation3'],row['User3']))\n",
    "        pair_tuples.append((row['Annotation3'],row['User3'],row['Annotation2'],row['User2']))\n",
    "    df_user_pair=pd.DataFrame(pair_tuples,columns=['Annotation1','User1','Annotation2','User2'])\n",
    "    df_user_pair=df_user_pair[(df_user_pair['User1']==username)|(df_user_pair['User2']==username)]\n",
    "    if(len(df_user_pair)>0):\n",
    "        avg_agreement=[]\n",
    "        for user in user_dict_keyname:\n",
    "            if(user!=username):\n",
    "                temp=df_user_pair[(df_user_pair['User1']==user)|(df_user_pair['User2']==user)]\n",
    "                user1=[]\n",
    "                user2=[]\n",
    "                for index,row in temp.iterrows():\n",
    "                    if(row['User1']==username):\n",
    "                        user1.append(row['Annotation1'])\n",
    "                        user2.append(row['Annotation2'])\n",
    "                    else:\n",
    "                        user1.append(row['Annotation2'])\n",
    "                        user2.append(row['Annotation1'])\n",
    "                        \n",
    "                if(len(user1)>0):\n",
    "                    temp=cohen_kappa_score(user1, user2)\n",
    "                    if(math.isnan(temp)):\n",
    "                        temp=1\n",
    "                    \n",
    "                    avg_agreement.append(temp)\n",
    "        \n",
    "        return np.mean(avg_agreement),int(len(df_user_pair)/2)\n",
    "    else:\n",
    "        print(\"User has not annotated yet\")\n",
    "        return 0.0,0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\r",
      "  0%|          | 0/4448 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/frame.py:3155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc[index, col] = value\n",
      "100%|██████████| 4448/4448 [00:04<00:00, 919.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========X=====================X======\n",
      "fleiss kappa 0.3839099859353024\n",
      "=====================================\n",
      "Divyanshu_cohens_kappa 0.39338102739280234\n",
      "Divyanshu_count_annotation 116\n",
      "User has not annotated yet\n",
      "Debayu_cohens_kappa 0.0\n",
      "Debayu_count_annotation 0.0\n",
      "User has not annotated yet\n",
      "Danish_cohens_kappa 0.0\n",
      "Danish_count_annotation 0.0\n",
      "Sharat_cohens_kappa 0.410525046822381\n",
      "Sharat_count_annotation 117\n",
      "Kukkadapu_cohens_kappa 0.3680009335613725\n",
      "Kukkadapu_count_annotation 116\n",
      "Adarsh_cohens_kappa 0.27434770975155065\n",
      "Adarsh_count_annotation 117\n",
      "Yuvraj_cohens_kappa 0.4356927396082562\n",
      "Yuvraj_count_annotation 116\n",
      "Vineeth_cohens_kappa 0.2768137397636143\n",
      "Vineeth_count_annotation 117\n",
      "User has not annotated yet\n",
      "Samanway_cohens_kappa 0.0\n",
      "Samanway_count_annotation 0.0\n",
      "Annotations done: 699.0\n",
      "Annotations LEFT: 0.0\n",
      "Fear speech: 69    Normal: 164\n",
      "==========X=====================X======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\r",
      "  0%|          | 0/4448 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/frame.py:3155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc[index, col] = value\n",
      "100%|██████████| 4448/4448 [00:04<00:00, 936.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========X=====================X======\n",
      "fleiss kappa 0.3687189436836963\n",
      "=====================================\n",
      "Divyanshu_cohens_kappa 0.3404358424049194\n",
      "Divyanshu_count_annotation 237\n",
      "Debayu_cohens_kappa 0.36275070554720035\n",
      "Debayu_count_annotation 235\n",
      "User has not annotated yet\n",
      "Danish_cohens_kappa 0.0\n",
      "Danish_count_annotation 0.0\n",
      "Sharat_cohens_kappa 0.3646217929456263\n",
      "Sharat_count_annotation 228\n",
      "Kukkadapu_cohens_kappa 0.4060990875281553\n",
      "Kukkadapu_count_annotation 235\n",
      "Adarsh_cohens_kappa 0.3414819123492655\n",
      "Adarsh_count_annotation 200\n",
      "Yuvraj_cohens_kappa 0.46136981352118484\n",
      "Yuvraj_count_annotation 233\n",
      "User has not annotated yet\n",
      "Vineeth_cohens_kappa 0.0\n",
      "Vineeth_count_annotation 0.0\n",
      "User has not annotated yet\n",
      "Samanway_cohens_kappa 0.0\n",
      "Samanway_count_annotation 0.0\n",
      "Annotations done: 1368.0\n",
      "Annotations LEFT: 171.0\n",
      "Fear speech: 126    Normal: 330\n",
      "==========X=====================X======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\r",
      "  0%|          | 0/4448 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/frame.py:3155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc[index, col] = value\n",
      "100%|██████████| 4448/4448 [00:04<00:00, 950.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========X=====================X======\n",
      "fleiss kappa 0.3337758735139702\n",
      "=====================================\n",
      "Divyanshu_cohens_kappa 0.34218651499973013\n",
      "Divyanshu_count_annotation 354\n",
      "Debayu_cohens_kappa 0.2033482738461298\n",
      "Debayu_count_annotation 356\n",
      "User has not annotated yet\n",
      "Danish_cohens_kappa 0.0\n",
      "Danish_count_annotation 0.0\n",
      "Sharat_cohens_kappa 0.3354227795931771\n",
      "Sharat_count_annotation 347\n",
      "Kukkadapu_cohens_kappa 0.4006478746988565\n",
      "Kukkadapu_count_annotation 271\n",
      "User has not annotated yet\n",
      "Adarsh_cohens_kappa 0.0\n",
      "Adarsh_count_annotation 0.0\n",
      "Yuvraj_cohens_kappa 0.3133752113248425\n",
      "Yuvraj_count_annotation 144\n",
      "Vineeth_cohens_kappa 0.15665374677002586\n",
      "Vineeth_count_annotation 28\n",
      "User has not annotated yet\n",
      "Samanway_cohens_kappa 0.0\n",
      "Samanway_count_annotation 0.0\n",
      "Annotations done: 1500.0\n",
      "Annotations LEFT: 0.0\n",
      "Fear speech: 105    Normal: 395\n",
      "==========X=====================X======\n",
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  0%|          | 0/4448 [00:00<?, ?it/s]/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/frame.py:3155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc[index, col] = value\n",
      "  2%|▏         | 90/4448 [00:00<00:04, 896.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [00:04<00:00, 937.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========X=====================X======\n",
      "fleiss kappa 0.4007596718657193\n",
      "=====================================\n",
      "Divyanshu_cohens_kappa 0.44633249898256394\n",
      "Divyanshu_count_annotation 375\n",
      "Debayu_cohens_kappa 0.3608266478784188\n",
      "Debayu_count_annotation 375\n",
      "User has not annotated yet\n",
      "Danish_cohens_kappa 0.0\n",
      "Danish_count_annotation 0.0\n",
      "User has not annotated yet\n",
      "Sharat_cohens_kappa 0.0\n",
      "Sharat_count_annotation 0.0\n",
      "Kukkadapu_cohens_kappa 0.4116781302080224\n",
      "Kukkadapu_count_annotation 374\n",
      "User has not annotated yet\n",
      "Adarsh_cohens_kappa 0.0\n",
      "Adarsh_count_annotation 0.0\n",
      "Yuvraj_cohens_kappa 0.384599370779744\n",
      "Yuvraj_count_annotation 376\n",
      "User has not annotated yet\n",
      "Vineeth_cohens_kappa 0.0\n",
      "Vineeth_count_annotation 0.0\n",
      "User has not annotated yet\n",
      "Samanway_cohens_kappa 0.0\n",
      "Samanway_count_annotation 0.0\n",
      "Annotations done: 1500.0\n",
      "Annotations LEFT: 0.0\n",
      "Fear speech: 136    Normal: 364\n",
      "==========X=====================X======\n",
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  0%|          | 0/4448 [00:00<?, ?it/s]/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/frame.py:3155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.loc[index, col] = value\n",
      "  3%|▎         | 114/4448 [00:00<00:03, 1139.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4448/4448 [00:04<00:00, 957.67it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========X=====================X======\n",
      "fleiss kappa 0.2794663964876731\n",
      "=====================================\n",
      "Divyanshu_cohens_kappa 0.2671411726594827\n",
      "Divyanshu_count_annotation 176\n",
      "User has not annotated yet\n",
      "Debayu_cohens_kappa 0.0\n",
      "Debayu_count_annotation 0.0\n",
      "User has not annotated yet\n",
      "Danish_cohens_kappa 0.0\n",
      "Danish_count_annotation 0.0\n",
      "Sharat_cohens_kappa 0.22586486003923006\n",
      "Sharat_count_annotation 51\n",
      "Kukkadapu_cohens_kappa 0.24472626942498238\n",
      "Kukkadapu_count_annotation 175\n",
      "User has not annotated yet\n",
      "Adarsh_cohens_kappa 0.0\n",
      "Adarsh_count_annotation 0.0\n",
      "Yuvraj_cohens_kappa 0.4518105184435982\n",
      "Yuvraj_count_annotation 180\n",
      "Vineeth_cohens_kappa 0.20649620981083025\n",
      "Vineeth_count_annotation 171\n",
      "User has not annotated yet\n",
      "Samanway_cohens_kappa 0.0\n",
      "Samanway_count_annotation 0.0\n",
      "Annotations done: 753.0\n",
      "Annotations LEFT: 747.0\n",
      "Fear speech: 51    Normal: 200\n",
      "==========X=====================X======\n"
     ]
    }
   ],
   "source": [
    "round_to_consider=10\n",
    "annotation_data='../Data/Annotations_to_send/'\n",
    "fear_total=0\n",
    "normal_total=0\n",
    "fix_len=len(processed_df)\n",
    "for round_info in range(6,round_to_consider+1):\n",
    "    if round_info <3:\n",
    "        sample_df = pd.read_pickle(annotation_data+'annotation_'+str(round_info)+'.pkl')\n",
    "    elif round_info >=3:\n",
    "        temp_orig = pd.read_pickle(annotation_data+'annotation_'+str(round_info)+'.pkl')\n",
    "        orig_index_list=[int(ele) for ele in list(temp_orig['orig_index'].values)]\n",
    "        print(\"hello\")\n",
    "#         list_indexes=[]\n",
    "#         for key in tqdm.tqdm(dict_ids_annotation, total=len(dict_ids_annotation)):\n",
    "#             list_indexes.append(key-len(processed_df))\n",
    "        sample_df=processed_df[processed_df['orig_index'].isin(orig_index_list)]\n",
    "        print(len(sample_df))\n",
    "    else:\n",
    "        print(\"No such file exist\")\n",
    "        continue\n",
    "    sample_df['Annotation1']= ['No_Annotation']*len(sample_df)\n",
    "    sample_df['Annotation2']= ['No_Annotation']*len(sample_df)\n",
    "    sample_df['Annotation3']= ['No_Annotation']*len(sample_df)\n",
    "    sample_df['User1']= ['No_User']*len(sample_df)\n",
    "    sample_df['User2']= ['No_User']*len(sample_df)\n",
    "    sample_df['User3']= ['No_User']*len(sample_df)\n",
    "    \n",
    "    for key in tqdm.tqdm(dict_ids_annotation,total=len(dict_ids_annotation)):\n",
    "        try:\n",
    "#             if(len(dict_ids_annotation[key])!=3):\n",
    "#                 continue\n",
    "            #print(dict_user_annotation)\n",
    "            res = uniqueIndexes(dict_user_annotation[key])    \n",
    "#             if(len(res) < 3):\n",
    "#                 continue\n",
    "            \n",
    "            count=1\n",
    "            for i in res:\n",
    "                if(count>3):\n",
    "                    break\n",
    "                #print(key,dict_user_annotation[key])\n",
    "                if(round_info<3):\n",
    "                    sample_df.loc[key]['Annotation'+str(count)]=dict_ids_annotation[key][i]\n",
    "                    sample_df.loc[key]['User'+str(count)] =dict_user_annotation[key][i]\n",
    "                else:\n",
    "                    key1=key-fix_len\n",
    "                    sample_df.at[key1,'Annotation'+str(count)]=dict_ids_annotation[key][i]\n",
    "                    sample_df.at[key1,'User'+str(count)]=dict_user_annotation[key][i]\n",
    "                count+=1\n",
    "        except KeyError or IndexError:\n",
    "            print(\"key error or index error\")\n",
    "            pass\n",
    "    sample_df=sample_df.dropna()\n",
    "    annotated_df=sample_df[~((sample_df['Annotation1']=='No_Annotation') | (sample_df['Annotation2']=='No_Annotation') | ( sample_df['Annotation3']=='No_Annotation'))]\n",
    "    annotation_data_receive='../Data/Annotations_received/'\n",
    "    sample_df.to_pickle(annotation_data_receive+'annotation_recv_'+str(round_info)+'.pkl')\n",
    "    \n",
    "    if(len(annotated_df)==0):\n",
    "        continue\n",
    "    print(\"==========X=====================X======\")\n",
    "    current_fleiss=return_fleiss_kappa(annotated_df)\n",
    "    print(\"fleiss kappa\",current_fleiss)\n",
    "#     if(len(annotated_df)==len(sample_df)):\n",
    "#         neptune.log_metric('fleiss_current_round',current_fleiss)\n",
    "    print(\"=====================================\")\n",
    "    total_annotations=0\n",
    "    for user in user_dict_keyname:\n",
    "        cohen_kappa,count_user=return_cohen_kappa_onevs_all(annotated_df,user)\n",
    "        print(user+'_cohens_kappa',cohen_kappa)\n",
    "        print(user+'_count_annotation',count_user)\n",
    "        total_annotations+=count_user\n",
    "#         if(len(annotated_df)==len(sample_df)):\n",
    "#             neptune.log_metric(user+'_cohens_kappa',cohen_kappa)\n",
    "#             neptune.log_metric(user+'_count_annotation',count_user)\n",
    "    \n",
    "    print(\"Annotations done:\",total_annotations)\n",
    "    print(\"Annotations LEFT:\",(len(sample_df)*3-total_annotations))\n",
    "    fear,normal=return_class_count(annotated_df)\n",
    "    print(\"Fear speech:\",fear,'   Normal:',normal)\n",
    "    fear_total+=fear\n",
    "    normal_total+=normal\n",
    "#     if(len(annotated_df)==len(sample_df)):\n",
    "#         neptune.log_metric('annotation_total',fear_total+normal_total)\n",
    "#         neptune.log_metric('fear_speech_found',fear_total)\n",
    "    print(\"==========X=====================X======\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleiss Kappa till this round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "annotation_data_receive='../Data/Annotations_received/*'\n",
    "files=glob.glob(annotation_data_receive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Data/Annotations_received/annotation_recv_6.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_1.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_8.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_3.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_2.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_9.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_5.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_7.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_0.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_10.pkl',\n",
       " '../Data/Annotations_received/annotation_recv_4.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2=d2.drop(list(set(d1.index).intersection(set(d2.index))))\n",
    "# d2.to_pickle(files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../Data/Annotations_received/annotation_recv_0.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_1.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_10.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_2.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_3.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_4.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_5.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_6.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_7.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_8.pkl',\n",
       "       '../Data/Annotations_received/annotation_recv_9.pkl'], dtype='<U51')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=np.sort(files)\n",
    "files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round ../Data/Annotations_received/annotation_recv_0.pkl\n",
      "Fear speech 169\n",
      "Normal 296\n",
      "Not decided 0\n",
      "Fleiss Kappa 1.0\n",
      "Round ../Data/Annotations_received/annotation_recv_1.pkl\n",
      "Fear speech 25\n",
      "Normal 475\n",
      "Not decided 0\n",
      "Fleiss Kappa 0.3154593050286711\n",
      "Round ../Data/Annotations_received/annotation_recv_10.pkl\n",
      "Fear speech 89\n",
      "Normal 358\n",
      "Not decided 53\n",
      "Fleiss Kappa 0.2794663964876731\n",
      "Round ../Data/Annotations_received/annotation_recv_2.pkl\n",
      "Fear speech 47\n",
      "Normal 416\n",
      "Not decided 0\n",
      "Fleiss Kappa 0.3476565380927798\n",
      "Round ../Data/Annotations_received/annotation_recv_3.pkl\n",
      "Fear speech 125\n",
      "Normal 491\n",
      "Not decided 0\n",
      "Fleiss Kappa 0.35999843038769436\n",
      "Round ../Data/Annotations_received/annotation_recv_4.pkl\n",
      "Fear speech 147\n",
      "Normal 387\n",
      "Not decided 1\n",
      "Fleiss Kappa 0.2649419165383121\n",
      "Round ../Data/Annotations_received/annotation_recv_5.pkl\n",
      "Fear speech 242\n",
      "Normal 610\n",
      "Not decided 0\n",
      "Fleiss Kappa 0.3580055056638725\n",
      "Round ../Data/Annotations_received/annotation_recv_6.pkl\n",
      "Fear speech 69\n",
      "Normal 164\n",
      "Not decided 0\n",
      "Fleiss Kappa 0.3839099859353024\n",
      "Round ../Data/Annotations_received/annotation_recv_7.pkl\n",
      "Fear speech 134\n",
      "Normal 360\n",
      "Not decided 19\n",
      "Fleiss Kappa 0.3687189436836963\n",
      "Round ../Data/Annotations_received/annotation_recv_8.pkl\n",
      "Fear speech 105\n",
      "Normal 395\n",
      "Not decided 0\n",
      "Fleiss Kappa 0.3337758735139702\n",
      "Round ../Data/Annotations_received/annotation_recv_9.pkl\n",
      "Fear speech 136\n",
      "Normal 364\n",
      "Not decided 0\n",
      "Fleiss Kappa 0.4007596718657193\n"
     ]
    }
   ],
   "source": [
    "list_df=[]\n",
    "for file in files:\n",
    "    \n",
    "    df=pd.read_pickle(file)\n",
    "    temp=return_atleast_one_count(df)\n",
    "    try:\n",
    "        fleiss_till_now = return_fleiss_kappa(temp)\n",
    "    except:\n",
    "        fleiss_till_now=0\n",
    "    print('Round',file)\n",
    "    print('Fear speech',len(temp[temp['one_fear_speech']==1]))\n",
    "    print('Normal',len(temp[temp['one_fear_speech']==0]))\n",
    "    print('Not decided',len(temp[temp['one_fear_speech']==-1]))\n",
    "    print('Fleiss Kappa',fleiss_till_now)\n",
    "    list_df.append(temp)\n",
    "    \n",
    "\n",
    "total_df = pd.concat(list_df)\n",
    "#total_df = total_df.loc[~total_df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5677"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files\n",
    "df=pd.read_pickle('../Data/Annotations_received/annotation_recv_9.pkl')\n",
    "df[df['Annotation2']!=\"No_Annotation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_orig = pd.read_pickle(annotation_data+'annotation_'+str(8)+'.pkl')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[total_df['one_fear_speech']==0][['message_text']].sample(10).to_csv('10_normal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pilot=[5585410.0,\n",
    "247024.0,\n",
    "692000.0,\n",
    "4822751.0,\n",
    "5322724.0,\n",
    "5256635.0,\n",
    "6061616.0,\n",
    "4792247.0,\n",
    "1307247.0,\n",
    "5223302.0,\n",
    "4053832.0,\n",
    "2641753.0,\n",
    "1493359.0,\n",
    "5254564.0,\n",
    "236647.0,]\n",
    "\n",
    "df[df['orig_index'].isin(index_pilot)][['message_text','Annotation1','Annotation2','Annotation3','User1','User2','User3']].to_csv('pilot_recv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 600)\n",
    "\n",
    "last_round_df=list_df[4]\n",
    "user_to_check='Vineeth'\n",
    "\n",
    "sample_user=last_round_df[(last_round_df['User1']==user_to_check) | (last_round_df['User3']==user_to_check) | (last_round_df['User3']==user_to_check)]\n",
    "sample_user[['message_text','Annotation1','Annotation2','Annotation3','User1','User2','User3']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_round_df=list_df[3]\n",
    "user1='Divyanshu'\n",
    "sample_new=last_round_df[~(last_round_df['User1'].isin([user1]))]\n",
    "sample_new=sample_new[~(sample_new['User2'].isin([user1]))]\n",
    "sample_new=sample_new[~(sample_new['User3'].isin([user1]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(annotated_df)==len(sample_df)):\n",
    "    neptune.log_metric('fleiss_kappa_total',fleiss_till_now)\n",
    "    neptune.log_metric('annotation_total',total_annotated)\n",
    "    neptune.log_metric('fear_speech_found',fear)\n",
    "    \n",
    "else:\n",
    "    print('fleiss_kappa_total',fleiss_till_now)\n",
    "    print('annotation_total',total_annotated)\n",
    "    print('fear speech',fear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_atleast_one_count(df):\n",
    "    dict_map={'Fear speech':1,'Normal':0, 'No_Annotation':2}\n",
    "    fear_count=[]\n",
    "    for index,row in df.iterrows():\n",
    "        annotation_list=[0,0,0]\n",
    "        annotation_list[dict_map[row['Annotation1']]]+=1\n",
    "        annotation_list[dict_map[row['Annotation2']]]+=1\n",
    "        annotation_list[dict_map[row['Annotation3']]]+=1\n",
    "        if(annotation_list[1]>=2):\n",
    "            fear_count.append(1)\n",
    "        elif(annotation_list[0]>=2):\n",
    "            fear_count.append(0)\n",
    "        else:\n",
    "            fear_count.append(-1)\n",
    "        #listM.append(annotation_list)\n",
    "    df['one_fear_speech']=fear_count\n",
    "    #sample_df=df[df['one_fear_speech']==1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_round_df=return_atleast_one_count(last_round_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_agreement=last_round_df[last_round_df['one_fear_speech'].isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_disagreement_fear_speech={}\n",
    "dict_disagreement_normal={}\n",
    "list_minimum_user=[]\n",
    "\n",
    "for index,row in tqdm_notebook(sample_agreement.iterrows(),total=len(sample_agreement)):\n",
    "    list_annotation={'Fear speech':[],'Normal':[]}\n",
    "    \n",
    "    for i in range(1,4):\n",
    "        try:\n",
    "            temp=row['Annotation'+str(i)]\n",
    "            list_annotation[temp].append(row['User'+str(i)])\n",
    "        except:\n",
    "            pass\n",
    "    print(list_annotation)    \n",
    "    if(len(list_annotation['Fear speech'])>len(list_annotation['Normal'])  and len(list_annotation['Normal'])==1):\n",
    "        list_minimum_user.append(list_annotation['Normal'][0])\n",
    "        try:\n",
    "            dict_disagreement_normal[list_annotation['Normal'][0]]+=1\n",
    "        except:\n",
    "            dict_disagreement_normal[list_annotation['Normal'][0]]=1\n",
    "    elif(len(list_annotation['Fear speech'])<len(list_annotation['Normal']) and len(list_annotation['Fear speech'])==1):\n",
    "        list_minimum_user.append(list_annotation['Fear speech'][0])\n",
    "        try:\n",
    "            dict_disagreement_fear_speech[list_annotation['Fear speech'][0]]+=1\n",
    "        except:\n",
    "            dict_disagreement_fear_speech[list_annotation['Fear speech'][0]]=1\n",
    "    \n",
    "    else:\n",
    "        list_minimum_user.append('None')\n",
    "    \n",
    "sample_agreement['minority']=list_minimum_user\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check high mistake users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "#last_round_df=list_df[4]\n",
    "user_to_check='Yuvraj'\n",
    "sample_user=sample_agreement[sample_agreement['minority']==user_to_check]\n",
    "sample_user[['message_text','Annotation1','Annotation2','Annotation3','User1','User2','User3']].to_csv(user_to_check+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_disagreement_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df=return_atleast_one_count(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('atleast_one_fear.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "puncts=[\"-\",\".\",\"''\",\"``\",\"'\",\"|\",\"​\",\"!\",\",\"]\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "#import nltk\n",
    "from cltk.tokenize.word import WordTokenizer\n",
    "#from nltk.corpus import stopwords\n",
    "from cltk.stop.classical_hindi.stops import STOPS_LIST\n",
    "tok = WordTokenizer(language='multilingual')\n",
    "## libraries that can be used\n",
    "def preprocess(df,params=None):\n",
    "    '''This function should implememnt a multi-lingual tokenizer '''\n",
    "    '''input: a document / sentence , params is a dict of control sequence'''\n",
    "    '''output: should return a token list for the entire document/sentence'''\n",
    "    list_tokenized=[]\n",
    "    for index,row in tqdm_notebook(df.iterrows(),total=len(df)):\n",
    "        s = row['message_text']\n",
    "        s = emoji.demojize(s)\n",
    "        s = re.sub(r\"http\\S+\",'', s)\n",
    "        s = re.sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"\",s)\n",
    "        s = re.sub(r\"/-\", \" \",s)\n",
    "        s = re.sub(r\"#,?,\\,\", \" \",s)\n",
    "        s = re.sub(r\"[:\\*]\",\" \",s)\n",
    "        s=re.sub('[' + re.escape(''.join(puncts)) + ']', '', s)\n",
    "        s=s.lower()\n",
    "        msg= tok.tokenize(s)\n",
    "        list_tokenized.append(msg)\n",
    "        \n",
    "    df['tokenized']=list_tokenized\n",
    "    return df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df=preprocess(sample_df,params=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='../Data/Important_lexicon/'+'muslim'+'_keywords.txt'\n",
    "keyword_text = open(filename, 'r')\n",
    "keywords = [line.strip('\\n').lower() for line in keyword_text.readlines()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fear_speech_keyword_count={}\n",
    "normal_keyword_count={}\n",
    "\n",
    "for index,row in tqdm_notebook(sample_df.iterrows(),total=len(sample_df)):\n",
    "    temp = row['tokenized']\n",
    "    for keyword in set(temp):\n",
    "        if(row['one_fear_speech']==1):\n",
    "            try:\n",
    "                fear_speech_keyword_count[keyword]+=1\n",
    "            except KeyError:\n",
    "                fear_speech_keyword_count[keyword]=1\n",
    "        \n",
    "        if(row['one_fear_speech']==0):\n",
    "            try:\n",
    "                normal_keyword_count[keyword]+=1\n",
    "            except KeyError:\n",
    "                normal_keyword_count[keyword]=1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_keyword_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1={k: v for k, v in sorted(normal_keyword_count.items(), key=lambda item: item[1],reverse=True)}\n",
    "dict2={k: v for k, v in sorted(fear_speech_keyword_count.items(), key=lambda item: item[1],reverse=True)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocab=[]\n",
    "for word,count in Counter(dict2).most_common(10000):\n",
    "    try:\n",
    "        temp=dict1[word]\n",
    "        vocab.append(count)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_child = np.array([dict2[word] for word in vocab])\n",
    "x_base = np.array([dict1[word] for word in vocab]) + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.log(x_base) - np.log(x_base.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = estimate(x_child,mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('normal_keyword_count.json', 'w') as fp:\n",
    "    json.dump(dict1, fp,indent=4,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_order_difference(dict1,dict2,max_rank=40):\n",
    "    tuples_A=sorted(dict1.items(), key=lambda item: item[1],reverse=True)\n",
    "    tuples_B=sorted(dict2.items(), key=lambda item: item[1],reverse=True)\n",
    "    \n",
    "    dict_A={}\n",
    "    count=0\n",
    "    for ele in tuples_A:\n",
    "        if(count<max_rank):\n",
    "            count+=1\n",
    "        dict_A[ele[0]]=count\n",
    "    \n",
    "    dict_B={}\n",
    "    count=0\n",
    "    for ele in tuples_B:\n",
    "        if(count<max_rank):\n",
    "            count+=1\n",
    "        dict_B[ele[0]]=count\n",
    "    \n",
    "    rank_diff_A={}\n",
    "    for key in dict_A.keys():\n",
    "        try:\n",
    "            rank_diff_A[key]=dict_B[key]-dict_A[key]\n",
    "        except:\n",
    "            rank_diff_A[key]=max_rank-dict_A[key]\n",
    "    rank_diff_B={}\n",
    "    for key in dict_B.keys():\n",
    "        try:\n",
    "            rank_diff_B[key]=dict_A[key]-dict_B[key]\n",
    "        except:\n",
    "            rank_diff_B[key]=max_rank-dict_B[key]\n",
    "            \n",
    "    return rank_diff_A,rank_diff_B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_diff_A, rank_diff_B=rank_order_difference(dict1,dict2,max_rank=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hashtag=sorted(rank_diff_B.items(), key=lambda item: item[1],reverse=True)[0:30]\n",
    "[ele[0] for ele in list_hashtag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-.conda-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
